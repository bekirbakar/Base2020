# Awesome Speech Processing

A curated list of resources for speech processing experiments, tasks, and projects.

## Libraries and Frameworks

- [HTK](https://htk.eng.cam.ac.uk): A Portable Toolkit For Building And Manipulating Hidden Markov Models (C)
- [Kaldi](https://kaldi-asr.org): Speech Recognition Toolkit (C++)
- [SIDEKIT](https://projets-lium.univ-lemans.fr/sidekit): Open Source Package for Speaker and Language Recognition (Python)
- [Kaldi with Torch](https://github.com/mravanelli/pytorch-kaldi): The PyTorch-Kaldi Speech Recognition Toolkit (Python)
- [Leon](https://github.com/leon-ai/leon): Open Source Text and Speech Assistant (Python)

- [Awesome Kaldi Repository](https://github.com/YoavRamon/awesome-kaldi): This is a list of features, scripts, blogs and resources...

## Datasets and Models

- [Kaldi ASR Models](https://kaldi-asr.org/models.html)
- [Kaldi Downloads](http://www.kaldi-asr.org/downloads/tree/trunk/)
- [Open SLR](https://www.openslr.org/resources.php)
- [Mozilla Common Voice Datasets](https://commonvoice.mozilla.org/tr/datasets)
- [Free Spoken Digit Dataset](https://github.com/Jakobovski/free-spoken-digit-dataset)
- [LibriSpeech - Hugging Face](https://huggingface.co/datasets/librispeech_asr)
- [Coqui AI](https://coqui.ai)

## Language Models

- [How to train a language model?](https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html)

## Â Diarization

- [Speaker Diarization](https://github.com/pyannote)
  
## ASR with Transformers

### Fine Tune Multi-Lingual Speech Recognition Model With Transformers Using CTC

- [Self-supervised Cross-lingual Speech Representation Learning at Scale (XLS-R)](https://arxiv.org/pdf/2111.09296.pdf)
- [Hugging Face Base Repo](https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-recognition) for all ASR examples using transformers.

- [Fine-tuning Multi-Lingual Speech Model with ðŸ¤— Transformers](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multi_lingual_speech_recognition.ipynb#scrollTo=d2G6z5RGAq5p)
- [Automatic Speech Recognition Examples - HUgging Face - Common Voice](https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-recognition/#common-voice-ctc)

## Further Reading

- Torch Start Locally
- Cuda Data Transfers
- Common Voice
- Hugging Face - Common Voice
- Wav2vec 2.0: Learning the structure of speech from raw audio
- XLM-R: State-of-the-art cross-lingual understanding through self-supervision
- XLS-R: Self-supervised speech processing for 128 languages
- Sequence Modeling With CTC
- Metric: WER
- Repo: wav2letter
- Unsupervised Cross-lingual Representation Learning for Speech Recognition
- ValueError: Mixed precision training with AMP or APEX (`â€“fp16`) and FP16 evaluation can only be used on CUDA devices
- Avoiding Cuda Out of Memory
- Runtime Error: Input Type and Weight Type

- <https://www.interactions.com/conversational-ai>
- <https://commonvoice.mozilla.org/en/datasets>
- <https://www.clsp.jhu.edu/wp-content/uploads/2016/06/Building-Speech-Recognition-Systems-with-the-Kaldi-Toolkit.pdf>
- <https://commonvoice.mozilla.org>
- <https://huggingface.co/metrics/wer>
- <https://www.youtube.com/playlist?list=PLxbPHSSMPBeicXAHVfyFvGfCywRCq39Mp>
- <https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio>
- <https://github.com/Jakobovski/free-spoken-digit-dataset>
- <https://pytorch.org>
- <http://www.danielpovey.com/kaldi-lectures.html>
- <https://gitlab.mobildev.in/datamin-v2/datamin_v2_speech_to_text/-/wikis/Hugging-Face-Guide>
- <https://huggingface.co/datasets/common_voice>
- <https://stackoverflow.com/questions/59129812/how-to-avoid-cuda-out-of-memory-in-pytorch>
- <https://www.ibm.com/cloud/learn/conversational-ai>
- <https://ai.facebook.com/blog/xls-r-self-supervised-speech-processing-for-128-languages>
- <https://coqui.ai/turkish/itml/v0.1.0>
- <http://www.practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/>
- <https://github.com/huggingface/transformers/tree/main/examples/pytorch/speech-recognition>
- <http://jrmeyer.github.io/asr/2016/12/15/DNN-AM-Kaldi.html>
- <https://paperswithcode.com/paper/unsupervised-cross-lingual-representation-3#code>
- <https://discuss.huggingface.co/t/valueerror-mixed-precision-training-with-amp-or-apex-fp16-and-fp16-evaluation-can-only-be-used-on-cuda-devices/6910/3>
- <https://stt.readthedocs.io/en/latest/LANGUAGE_MODEL.html>
- <https://github.com/flashlight/wav2letter>
- <https://pytorch.org/get-started/locally>
- <https://towardsdatascience.com/how-to-start-with-kaldi-and-speech-recognition-a9b7670ffff6>
- <https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec/xlsr>
- <https://cs.nyu.edu/~mohri/pub/hbka.pdf>
- <https://distill.pub/2017/ctc>
- <https://stackoverflow.com/questions/59013109/runtimeerror-input-type-torch-floattensor-and-weight-type-torch-cuda-floatte>
- <https://coqui.ai/models>
- <https://ai.facebook.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision>
- <https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc>
